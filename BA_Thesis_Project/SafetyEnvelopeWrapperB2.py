
import gymnasium as gym

from BA_Thesis_Project.SafetyEnvelopeWrapperB1 import SafetyEnvelopeWrapperB1

MAX_ADVANCE_ROBOT=0.1
MAX_ROTATION_ROBOT=1.57
# below this threshold, safe
ALERT_HUMAN_SAFE_THRESHOLD=0.3
# per step for high alert
ALERT_HUMAN_HIGH_PENALTY=-0.8
# mild penalty per step for any alertness_Human >0
ALERT_HUMAN_BASE_PENALTY=-0.2
# Wall alertness shaping (to avoid wall hugging), per step=ALERT_WALL_PENALTY*alertWall
ALERT_WALL_PENALTY=-0.6

# ALERT_NEAR_HUMAN_THRESHOLD=0.4
FAR_ROTATION_PENALTY=-0.2
# NEAR_ROTATION_BONUS=0.5


# forward speed bonus factor
SPEED_BONUS_SCALE=4.0
# never kill speed bonus completely
MIN_SPEED_FACTOR=0.3


class SafetyEnvelopeWrapperB2(SafetyEnvelopeWrapperB1):
    def __init__(self, env:gym.Env, ):
        super().__init__(env)



    def step(self, action):
        obs, reward, terminated, truncated, info= super().step(action)
        # forward speed, side speed from original action generated by the PPO -utility focused component
        forward_speed=max(0.0, action[0])*MAX_ADVANCE_ROBOT
        rotation_speed= abs(action[2])*MAX_ROTATION_ROBOT

        # USE ALERTNESS HUMAN TO MODULATE SPEED
        alertness_human= self.alertnessHuman

        # far from human-> big speed factor
        # near human -> smaller bonus , but not 0 to prevent freeze near human, encourage robot to move faster when not near human, move slower otherwise
        speed_factor=MIN_SPEED_FACTOR + (1.0-MIN_SPEED_FACTOR)*(1.0-alertness_human)
        speed_bonus= SPEED_BONUS_SCALE*forward_speed*speed_factor
        # max = 4*0.1*1=0.4
        reward+=speed_bonus

        # PENALISE ALERTNESS HUMAN -> ANTICIPATION
        # Intuition, if robot keep walking in a way that human alertness slowly increase, it gets negative every step-> learn to
        # deviate ealier so that alerthuman stay low

        # small penalty for any alertness
        reward+= ALERT_HUMAN_BASE_PENALTY*alertness_human
        # extra penalty if alertness is high (close to d_min)
        high_alertHuman= max(0.0, alertness_human-ALERT_HUMAN_SAFE_THRESHOLD)
        reward+= ALERT_HUMAN_HIGH_PENALTY*high_alertHuman

        # penalize rotation too early when still far from human -> aim to have short path to goal
        # if not near_human:
        #     reward+=FAR_ROTATION_PENALTY*rotation_speed
        # else:
        #     danger=(alertness_human-ALERT_NEAR_HUMAN_THRESHOLD)/(1.0-ALERT_HUMAN_SAFE_THRESHOLD)
        #     rotation_bonus=NEAR_ROTATION_BONUS*rotation_speed*danger
        #     reward+= rotation_bonus


        rotation_far_penalty=FAR_ROTATION_PENALTY*rotation_speed*(1-alertness_human)
        reward += rotation_far_penalty
        # PENALIZE WALL ALERTNESS -> prevent wall hugging
        alertness_wall= self.alertnessWall
        reward+= ALERT_WALL_PENALTY*alertness_wall


        return obs, reward, terminated, truncated, info





